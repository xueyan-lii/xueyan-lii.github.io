---
title: "Token-Level Uncertainty-Aware COT Reasoning"
collection: talks
type: "Talk"
permalink: /talks/2025-07-15
venue: "Ellis Institution"
date: 2025-07-15
location: "TÃ¼bingen, Germany"
link: /files/Project_update_2025-7-15.pdf
---

Token-level LLM uncertainty values contains rich information about calibration, step-wise entropy and model confidence. However, at each subsequent generation step, previous uncertainty values are discarded. How can we make use of this information to improve self-correction or chain-of-thought reasoning abilities in LLMs?
