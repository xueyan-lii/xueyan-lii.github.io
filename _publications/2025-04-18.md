---
title: "Confidence-as-Context: Persistent Uncertainty Signals for Autoregressive Generation"
collection: publications
category: ongoing
permalink: /publication/2025-04-18
excerpt: "Step-wise token uncertainties contain rich information on model confidence but are discarded after each step. We design a novel training and inference strategy and make these uncertainty signals persist throughout generation. All future generations are dependent on all past generation uncertainties. This method should allow models to self-assess accuracy and back-track, pause or continue, therefore achieving better chain-of-thought performance."
date: 2025-04-18
link: /files/Entropy_guided_generation.pdf
---

Modern autoregressive language models generate rich, step-wise signals of uncertainty over each token that correlate with calibration and correctness, yet these signals are transient and typically discarded before the next decoding step. We explore whether exposing this information back to the model can guide generation. We propose **entropy-guided interleaving**, a family of training and decoding schemes that interleave per-token confidence cues directly into the token stream. Specifically, we have three variations: Full-INTL (interleave across the entire sequence), Ans-INTL (interleave only in the answer span), and Reason-INTL (interleave only within marked reasoning segments). We provide an evaluation protocol on GSM8K and BIG-Bench-Mistak, along with attention-pattern and loss-dynamics observations, to understand how models make use of confidence signals. This work introduces a simple, general mechanism to make internal uncertainty explicitly available for guiding downstream generation.