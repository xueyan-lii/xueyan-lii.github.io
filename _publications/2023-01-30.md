---
title: "Performance of Various Loss Functions for Siamese Neural Networks"
collection: publications
category: coursework
permalink: /publication/2023-01-30
excerpt: "Compared binary cross-entropy, contrastive and triplet loss functions to classify 20 classes of images from
Tiny ImageNet. Compared ViT vs CNN architecture in terms of training data required, preservation of features across layers,
and the effect of skip connections."
date: 2023-01-30
link: /files/cv_coursework.pdf
---

Siamese neural network is effective for tasks involving image verification, where two images are identified to belong in the same category or not by passing through identical networks with shared weights. Popular loss functions for these parallel networks include binary cross-entropy, contrastive and triplet loss. In this paper, these three loss functions are implemented to verify 20 classes of images from Tiny ImageNet, based on a pre- trained ResNet50 model. Each model is first tuned by testing various embedding dimensions. Loss is investigated along with extent of clustering of images in embedding space to explain the difference in those loss functions. Experiments shows that binary cross-entropy loss performs best and that contrastive loss result in tighter clusters in the embedding space compared to triplet loss, which correlate well with mathematical interpretations of these loss functions.